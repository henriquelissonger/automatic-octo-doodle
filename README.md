
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2A. ConteÃºdo de README.md
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ðŸ§  Chat RAG â€“ PolÃ­ticas Internas

Um assistente que responde, em linguagem natural, dÃºvidas sobre polÃ­ticas corporativas.
Deploy: Docker â†’ Cloud Run, custo mÃ©dio â‰ˆ 0,002 $/req.

âœ¨ Funcionalidades
IngestÃ£o automÃ¡tica de documentos (PDF)
VetorizaÃ§Ã£o em Pinecone
Retrieval-Augmented Generation (RAG) com GPT-4o
API REST (FastAPI) + streaming
Monitoramento via OpenTelemetry â†’ Grafana Cloud

ðŸ”§ Arquiteturamermaid
flowchart LR
    A[UsuÃ¡rio] --> B[/Front-end\\/Chat widget/]
    B -->|POST /chat| C[FastAPI]
    C --> D(Pinecone Retriever)
    D --> E[Contexto]
    E --> F[GPT-4o]
    F --> C
    C -->|JSON| B

ðŸš€ Como rodar localmentebash
export OPENAI_API_KEY=sk-...
export PINECONE_API_KEY=...
docker build -t chat-rag .
docker run -p 8000:8000 \
  -e OPENAI_API_KEY \
  -e PINECONE_API_KEY chat-rag

ðŸ† MÃ©tricas
| MÃ©trica          | Valor |
|------------------|-------|
| LatÃªncia p95     | 1.2 s |
| Custo mÃ©dio      | 0.002 $ por requisiÃ§Ã£o |
| PrecisÃ£o manual  | 85 % |

ðŸ“„ LicenÃ§a
MIT

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2B. ConteÃºdo do Dockerfile
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FROM python:3.11-slim
WORKDIR /code
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY app app
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2C. requirements.txt
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
fastapi==0.110.0
uvicorn[standard]
langchain==0.1.17
openai==1.25.0
pinecone-client==3.2.2

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2D. app/main.py  (lembre-se de colocar o nome exatamente app/main.py)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from fastapi import FastAPI
from pydantic import BaseModel
import os, pinecone, openai
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Pinecone
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI

openai.api_key = os.getenv("OPENAI_API_KEY")
pinecone.init(api_key=os.getenv("PINECONE_API_KEY"), environment="gcp-starter")

index_name = "politicas-empresa"
embeddings = OpenAIEmbeddings()
vectorstore = Pinecone.from_existing_index(index_name, embeddings)
qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(model_name="gpt-4o", temperature=0.0, streaming=True),
    chain_type="stuff",
    retriever=vectorstore.as_retriever(search_kwargs={"k": 4})
)

class Question(BaseModel):
    query: str

app = FastAPI()

@app.post("/chat")
async def chat(question: Question):
    result = qa_chain({"query": question.query})
    return {"answer": result["result"]}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2E. n8n_workflow_lead_onboarding.json
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
{
  "nodes":[
    {"parameters":{"httpMethod":"POST","path":"lead-webhook"},
     "name":"Webhook Entrada","type":"n8n-nodes-base.webhook","typeVersion":1,"position":[300,300]},
    {"parameters":{"functionCode":"const email=$json[\"email\"];if(!email.includes(\"@\"))throw new Error(\"Email invÃ¡lido\");return[{json:{email}}];"},
     "name":"ValidaÃ§Ã£o de e-mail","type":"n8n-nodes-base.function","typeVersion":1,"position":[540,300]},
    {"parameters":{"operation":"append","sheetId":"1hKqETC_fake_id","range":"Leads!A:C"},
     "name":"Gravar no Google Sheets","type":"n8n-nodes-base.googleSheets","typeVersion":2,"position":[780,300]},
    {"parameters":{"authentication":"headerAuth","requestMethod":"POST","url":"https://api.hubspot.com/crm/v3/objects/contacts","jsonParameters":true,"bodyParametersJson":"{\"properties\":{\"email\":\"={{$json.email}}\"}}"},
     "name":"Criar contato HubSpot","type":"n8n-nodes-base.httpRequest","typeVersion":2,"position":[1020,300]}
  ],
  "connections":{
    "Webhook Entrada":{"main":[[{"node":"ValidaÃ§Ã£o de e-mail","type":"main","index":0}]]},
    "ValidaÃ§Ã£o de e-mail":{"main":[[{"node":"Gravar no Google Sheets","type":"main","index":0}]]},
    "Gravar no Google Sheets":{"main":[[{"node":"Criar contato HubSpot","type":"main","index":0}]]}
  }
}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2F. diagrams/architecture.puml
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
(No campo â€œNameâ€, digite exatamente diagrams/architecture.puml)
@startuml
!define ICONURL https://raw.githubusercontent.com/tupadr3/plantuml-icon-font-sprites/master
!includeurl ICONURL/common.puml
!includeurl ICONURL/devicons/openai.puml
!includeurl ICONURL/aws/cloudrun.puml
!includeurl ICONURL/devicons/pinecone.puml

actor User
cloud "Front-end\n(Chat widget)" as FE
component FastAPI
queue "Pinecone\nVector DB" as PC >
database "Docs\nBucket" as S3

User --> FE
FE --> FastAPI : POST /chat
FastAPI --> PC : Embeddings lookup
PC --> FastAPI : Top-K docs
FastAPI --> "OpenAI GPT-4o" > : Prompt + Context
"OpenAI GPT-4o" --> FastAPI : Resposta
FastAPI --> FE : JSON stream
FastAPI --> CloudRun > : Deploy target
@enduml

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 